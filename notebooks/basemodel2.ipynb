{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2q1rk1/pb3pbp/1ppp1np1/2nPp3/4P3/2P1B2P/PPBNN...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r7/ppQ1n2p/2n1k1p1/1N1p1q2/1P1P4/2P3P1/P7/2K5 ...</td>\n",
       "      <td>-929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r1bq1rk1/ppp1bppp/2n2n2/3Pp3/2B5/2PP1N1P/PP3PP...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6k1/R2b2r1/8/7R/2PPP3/8/7P/5K2 b - - 0 42</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r4r2/pp4pp/k1nQ1q2/5P2/2B5/8/P5PP/1R3RK1 b - -...</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980494</th>\n",
       "      <td>rnb1k2r/pp3ppp/4pn2/3pB3/8/P2PqN2/2PKPbPP/RN1Q...</td>\n",
       "      <td>-402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980495</th>\n",
       "      <td>6R1/pq1k1p2/1p1pp3/8/8/1P5r/P1PPQP1P/R5K1 w - ...</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980496</th>\n",
       "      <td>1r3rk1/pp4p1/1qn4p/4pp2/8/2NPPNP1/PP1Q1KbP/R7 ...</td>\n",
       "      <td>-357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980497</th>\n",
       "      <td>rnb1k1r1/pp3pBp/2pqp1p1/3P4/8/P1N2N2/1PP2PPP/R...</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980498</th>\n",
       "      <td>r1b2k2/6pp/3p4/3P1p2/ppp2P2/7B/4K1PP/4R3 w - -...</td>\n",
       "      <td>-576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960759 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       FEN  Evaluation\n",
       "0        r2q1rk1/pb3pbp/1ppp1np1/2nPp3/4P3/2P1B2P/PPBNN...          16\n",
       "1        r7/ppQ1n2p/2n1k1p1/1N1p1q2/1P1P4/2P3P1/P7/2K5 ...        -929\n",
       "2        r1bq1rk1/ppp1bppp/2n2n2/3Pp3/2B5/2PP1N1P/PP3PP...           4\n",
       "3                6k1/R2b2r1/8/7R/2PPP3/8/7P/5K2 b - - 0 42         546\n",
       "4        r4r2/pp4pp/k1nQ1q2/5P2/2B5/8/P5PP/1R3RK1 b - -...         684\n",
       "...                                                    ...         ...\n",
       "1980494  rnb1k2r/pp3ppp/4pn2/3pB3/8/P2PqN2/2PKPbPP/RN1Q...        -402\n",
       "1980495  6R1/pq1k1p2/1p1pp3/8/8/1P5r/P1PPQP1P/R5K1 w - ...         641\n",
       "1980496  1r3rk1/pp4p1/1qn4p/4pp2/8/2NPPNP1/PP1Q1KbP/R7 ...        -357\n",
       "1980497  rnb1k1r1/pp3pBp/2pqp1p1/3P4/8/P1N2N2/1PP2PPP/R...         686\n",
       "1980498  r1b2k2/6pp/3p4/3P1p2/ppp2P2/7B/4K1PP/4R3 w - -...        -576\n",
       "\n",
       "[3960759 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data01 = pd.read_csv('/home/suneel/Desktop/chess-engine/Data/Data Lake/Chess_1.csv')\n",
    "data02 = pd.read_csv('/home/suneel/Desktop/chess-engine/Data/Data Lake/Chess_2.csv')\n",
    "data03 = pd.concat([data01,data02],axis=0)\n",
    "data03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data03 = data03.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :  13.409747727645131\n",
      "std :  588.6268786929631\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "      <th>Evaluation_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>r2q1rk1/pb3pbp/1ppp1np1/2nPp3/4P3/2P1B2P/PPBNN...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>r7/ppQ1n2p/2n1k1p1/1N1p1q2/1P1P4/2P3P1/P7/2K5 ...</td>\n",
       "      <td>-929</td>\n",
       "      <td>-1.601031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>r1bq1rk1/ppp1bppp/2n2n2/3Pp3/2B5/2PP1N1P/PP3PP...</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.015986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6k1/R2b2r1/8/7R/2PPP3/8/7P/5K2 b - - 0 42</td>\n",
       "      <td>546</td>\n",
       "      <td>0.904801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>r4r2/pp4pp/k1nQ1q2/5P2/2B5/8/P5PP/1R3RK1 b - -...</td>\n",
       "      <td>684</td>\n",
       "      <td>1.139245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960754</th>\n",
       "      <td>1980494</td>\n",
       "      <td>rnb1k2r/pp3ppp/4pn2/3pB3/8/P2PqN2/2PKPbPP/RN1Q...</td>\n",
       "      <td>-402</td>\n",
       "      <td>-0.705727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960755</th>\n",
       "      <td>1980495</td>\n",
       "      <td>6R1/pq1k1p2/1p1pp3/8/8/1P5r/P1PPQP1P/R5K1 w - ...</td>\n",
       "      <td>641</td>\n",
       "      <td>1.066194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960756</th>\n",
       "      <td>1980496</td>\n",
       "      <td>1r3rk1/pp4p1/1qn4p/4pp2/8/2NPPNP1/PP1Q1KbP/R7 ...</td>\n",
       "      <td>-357</td>\n",
       "      <td>-0.629278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960757</th>\n",
       "      <td>1980497</td>\n",
       "      <td>rnb1k1r1/pp3pBp/2pqp1p1/3P4/8/P1N2N2/1PP2PPP/R...</td>\n",
       "      <td>686</td>\n",
       "      <td>1.142643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960758</th>\n",
       "      <td>1980498</td>\n",
       "      <td>r1b2k2/6pp/3p4/3P1p2/ppp2P2/7B/4K1PP/4R3 w - -...</td>\n",
       "      <td>-576</td>\n",
       "      <td>-1.001330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960759 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index                                                FEN  \\\n",
       "0              0  r2q1rk1/pb3pbp/1ppp1np1/2nPp3/4P3/2P1B2P/PPBNN...   \n",
       "1              1  r7/ppQ1n2p/2n1k1p1/1N1p1q2/1P1P4/2P3P1/P7/2K5 ...   \n",
       "2              2  r1bq1rk1/ppp1bppp/2n2n2/3Pp3/2B5/2PP1N1P/PP3PP...   \n",
       "3              3          6k1/R2b2r1/8/7R/2PPP3/8/7P/5K2 b - - 0 42   \n",
       "4              4  r4r2/pp4pp/k1nQ1q2/5P2/2B5/8/P5PP/1R3RK1 b - -...   \n",
       "...          ...                                                ...   \n",
       "3960754  1980494  rnb1k2r/pp3ppp/4pn2/3pB3/8/P2PqN2/2PKPbPP/RN1Q...   \n",
       "3960755  1980495  6R1/pq1k1p2/1p1pp3/8/8/1P5r/P1PPQP1P/R5K1 w - ...   \n",
       "3960756  1980496  1r3rk1/pp4p1/1qn4p/4pp2/8/2NPPNP1/PP1Q1KbP/R7 ...   \n",
       "3960757  1980497  rnb1k1r1/pp3pBp/2pqp1p1/3P4/8/P1N2N2/1PP2PPP/R...   \n",
       "3960758  1980498  r1b2k2/6pp/3p4/3P1p2/ppp2P2/7B/4K1PP/4R3 w - -...   \n",
       "\n",
       "         Evaluation  Evaluation_std  \n",
       "0                16        0.004400  \n",
       "1              -929       -1.601031  \n",
       "2                 4       -0.015986  \n",
       "3               546        0.904801  \n",
       "4               684        1.139245  \n",
       "...             ...             ...  \n",
       "3960754        -402       -0.705727  \n",
       "3960755         641        1.066194  \n",
       "3960756        -357       -0.629278  \n",
       "3960757         686        1.142643  \n",
       "3960758        -576       -1.001330  \n",
       "\n",
       "[3960759 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data04 = data03.copy()\n",
    "mean = data04['Evaluation'].mean()\n",
    "std = data04['Evaluation'].std()\n",
    "data04['Evaluation_std'] = (data04['Evaluation'] - mean) / std\n",
    "print(\"mean : \",mean)\n",
    "print(\"std : \",std)\n",
    "data04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encoding(fen):\n",
    "    '''\n",
    "    12 planes for each piece type (K, k, P, p, B, b, N, n, R, r, Q, q)\n",
    "    1 plane for empty spaces\n",
    "    1 plane for active color (1 for white, -1 for black)\n",
    "    4 planes for castling rights (K, Q, k, q)\n",
    "    1 plane for en passant target square (1 at the target square, 0 elsewhere)\n",
    "    1 plane for halfmove clock\n",
    "    1 plane for fullmove number\n",
    "    '''\n",
    "    # Piece indexing\n",
    "    piece_indexes = {\n",
    "        'K': 1, 'k': 2, 'P': 3, 'p': 4, 'B': 5, 'b': 6, 'N': 7, 'n': 8, \n",
    "        'R': 9, 'r': 10, 'Q': 11, 'q': 12\n",
    "    }\n",
    "\n",
    "    # Parse the FEN string\n",
    "    position, active, castling, enpassant, halfmove, fullmove = fen.split(' ')\n",
    "\n",
    "    # Initialize the encoded array with zeros\n",
    "    encoded = np.zeros((21, 8, 8))  # Updated to 21 channels\n",
    "\n",
    "    # Split the position into ranks (8 rows)\n",
    "    ranks = position.split('/')\n",
    "\n",
    "    # Encode the pieces and empty squares\n",
    "    for i in range(8):\n",
    "        rank = ranks[i]\n",
    "        ind = 0\n",
    "        for char in rank:\n",
    "            if char.isdigit():  # Empty squares\n",
    "                encoded[0, i, ind:ind+int(char)] = 1\n",
    "                ind += int(char)\n",
    "            else:\n",
    "                encoded[piece_indexes[char], i, ind] = 1\n",
    "                ind += 1\n",
    "\n",
    "    # Encode the active color (1 for white, -1 for black)\n",
    "    encoded[13] = 1 if active == 'w' else -1\n",
    "\n",
    "    # Encode castling rights (K, Q, k, q)\n",
    "    castling_map = {'K': 14, 'Q': 15, 'k': 16, 'q': 17}\n",
    "    for right in castling:\n",
    "        if right in castling_map:\n",
    "            encoded[castling_map[right]] = 1  # Set the entire plane to 1\n",
    "\n",
    "    # Encode en passant (1 at the en passant square, 0 elsewhere)\n",
    "    if enpassant != '-':\n",
    "        file, rank = ord(enpassant[0]) - ord('a'), 8 - int(enpassant[1])\n",
    "        encoded[18, rank, file] = 1\n",
    "\n",
    "    # Encode halfmove and fullmove counters\n",
    "    encoded[19] = int(halfmove)\n",
    "    encoded[20] = int(fullmove)\n",
    "\n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "fen = 'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1'\n",
    "#print(fen.split(' '))\n",
    "print(encoding(fen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "t1 = torch.tensor(encoding(fen))\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaseModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel2, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(21, 256, kernel_size=3, padding='same')\n",
    "        self.norm1 = nn.BatchNorm2d(256)\n",
    "        self.conv2 = nn.Conv2d(256, 256, kernel_size=3, padding='same')\n",
    "        self.norm2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.hiddenlayer1 = nn.Linear(256 * 8 * 8,256)  \n",
    "        self.norm3 = nn.BatchNorm1d(256)\n",
    "        self.hiddenlayer2 = nn.Linear(256, 512)\n",
    "        self.norm4 = nn.BatchNorm1d(512)\n",
    "        self.hiddenlayer3 = nn.Linear(512, 256)\n",
    "        self.norm5 = nn.BatchNorm1d(256)\n",
    "        self.output = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.norm1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.norm2(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.leaky_relu(self.norm3(self.hiddenlayer1(x)))\n",
    "        x = F.leaky_relu(self.norm4(self.hiddenlayer2(x)))\n",
    "        x = F.leaky_relu(self.norm5(self.hiddenlayer3(x)))\n",
    "\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class Chessloader(Dataset) :\n",
    "    def __init__(self,df) :\n",
    "        self.df = df\n",
    "    def __len__(self) :\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,ind) :\n",
    "        row = self.df.iloc[ind]\n",
    "        tensor = torch.tensor(encoding(row['FEN']),dtype=torch.float32).squeeze()\n",
    "        target = torch.tensor(row['Evaluation_std'], dtype=torch.float32)\n",
    "        return tensor,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data = train_test_split(data04.sample(2500000,random_state=42),test_size=0.20,random_state=42)\n",
    "train_data = train_data[train_data['Evaluation_std'].between(-3,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "      <th>Evaluation_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2349987</th>\n",
       "      <td>369727</td>\n",
       "      <td>1B6/8/4k3/8/5p2/5P2/5K2/8 w - - 5 54</td>\n",
       "      <td>539</td>\n",
       "      <td>0.892909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768825</th>\n",
       "      <td>1768825</td>\n",
       "      <td>rn1qkb1r/pppbpppp/3p4/8/2B1n3/3P1N2/PPP2PPP/RN...</td>\n",
       "      <td>-83</td>\n",
       "      <td>-0.163788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380644</th>\n",
       "      <td>400384</td>\n",
       "      <td>r2qkb1r/1p1nnpp1/p1p1p2p/3pPb2/2PP4/5N1P/PP2BP...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.021083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252723</th>\n",
       "      <td>252723</td>\n",
       "      <td>5N1B/1p1k1P2/3p1R2/2p1p3/P5Pp/6nK/4r3/R7 b - -...</td>\n",
       "      <td>665</td>\n",
       "      <td>1.106967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661834</th>\n",
       "      <td>681574</td>\n",
       "      <td>2rk1b1r/3b1Qp1/3p1p1p/1p1BpP2/pP1pP3/3P2RN/1q4...</td>\n",
       "      <td>-163</td>\n",
       "      <td>-0.299697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629622</th>\n",
       "      <td>1649362</td>\n",
       "      <td>r2q1rk1/pppbbppp/2n5/3p4/3PnP2/3BP3/PP1N2PP/R1...</td>\n",
       "      <td>56</td>\n",
       "      <td>0.072355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106623</th>\n",
       "      <td>126363</td>\n",
       "      <td>r6k/ppp4p/4bb2/4p2p/2P1Pp2/1P1r1N1P/P5PK/R1B3R...</td>\n",
       "      <td>-213</td>\n",
       "      <td>-0.384641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429332</th>\n",
       "      <td>449072</td>\n",
       "      <td>rnbqkb1r/3p1ppp/p3pn2/2pP4/2B1P3/2N5/PPP2PPP/R...</td>\n",
       "      <td>245</td>\n",
       "      <td>0.393442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631950</th>\n",
       "      <td>631950</td>\n",
       "      <td>r3k2B/p1qnb2p/6p1/5p2/3p4/1P2p3/P3Q1PP/RN3RK1 ...</td>\n",
       "      <td>336</td>\n",
       "      <td>0.548039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859011</th>\n",
       "      <td>859011</td>\n",
       "      <td>r3r1k1/1ppq2pp/p1n1b3/3pp3/PP1P2P1/2PB4/6P1/RN...</td>\n",
       "      <td>110</td>\n",
       "      <td>0.164094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1970849 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index                                                FEN  \\\n",
       "2349987   369727               1B6/8/4k3/8/5p2/5P2/5K2/8 w - - 5 54   \n",
       "1768825  1768825  rn1qkb1r/pppbpppp/3p4/8/2B1n3/3P1N2/PPP2PPP/RN...   \n",
       "2380644   400384  r2qkb1r/1p1nnpp1/p1p1p2p/3pPb2/2PP4/5N1P/PP2BP...   \n",
       "252723    252723  5N1B/1p1k1P2/3p1R2/2p1p3/P5Pp/6nK/4r3/R7 b - -...   \n",
       "2661834   681574  2rk1b1r/3b1Qp1/3p1p1p/1p1BpP2/pP1pP3/3P2RN/1q4...   \n",
       "...          ...                                                ...   \n",
       "3629622  1649362  r2q1rk1/pppbbppp/2n5/3p4/3PnP2/3BP3/PP1N2PP/R1...   \n",
       "2106623   126363  r6k/ppp4p/4bb2/4p2p/2P1Pp2/1P1r1N1P/P5PK/R1B3R...   \n",
       "2429332   449072  rnbqkb1r/3p1ppp/p3pn2/2pP4/2B1P3/2N5/PPP2PPP/R...   \n",
       "631950    631950  r3k2B/p1qnb2p/6p1/5p2/3p4/1P2p3/P3Q1PP/RN3RK1 ...   \n",
       "859011    859011  r3r1k1/1ppq2pp/p1n1b3/3pp3/PP1P2P1/2PB4/6P1/RN...   \n",
       "\n",
       "         Evaluation  Evaluation_std  \n",
       "2349987         539        0.892909  \n",
       "1768825         -83       -0.163788  \n",
       "2380644           1       -0.021083  \n",
       "252723          665        1.106967  \n",
       "2661834        -163       -0.299697  \n",
       "...             ...             ...  \n",
       "3629622          56        0.072355  \n",
       "2106623        -213       -0.384641  \n",
       "2429332         245        0.393442  \n",
       "631950          336        0.548039  \n",
       "859011          110        0.164094  \n",
       "\n",
       "[1970849 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Chessloader(train_data.sample(10000))\n",
    "test_set = Chessloader(test_data.sample(1000))\n",
    "train_loader = DataLoader(train_set,batch_size=32,shuffle=False)\n",
    "test_loader  = DataLoader(test_set,batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        mse_loss = self.mse(pred, target)\n",
    "        # Calculate scaling factor based on target values\n",
    "        scale = torch.log(math.e + self.alpha * torch.abs(target))\n",
    "        return (mse_loss * scale).mean()\n",
    "\n",
    "def train_model(model, train_loader, test_loader, epochs=40, lr=0.0005, alpha=1.0, checkpoint_dir='/home/suneel/Desktop/chess-engine/models/basemodel2/alpha1'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize losses\n",
    "    train_criterion = CustomLoss(alpha=alpha).to(device)\n",
    "    test_criterion = nn.MSELoss()  # Keep regular MSE for testing\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    # Track best model\n",
    "    best_test_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch [{epoch+1}/{epochs}] Training')\n",
    "        \n",
    "        for inputs, targets in train_pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.view(-1, 1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = train_criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            train_pbar.set_postfix({'train_loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_pbar = tqdm(test_loader, desc=f'Epoch [{epoch+1}/{epochs}] Testing')\n",
    "        \n",
    "        # Keep track of last 5 batches\n",
    "        last_5_predictions = []\n",
    "        last_5_actuals = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_pbar:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                targets = targets.view(-1, 1)\n",
    "                outputs = model(inputs)\n",
    "                loss = test_criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                test_pbar.set_postfix({'test_loss': f'{loss.item():.4f}'})\n",
    "                \n",
    "                # Store predictions and actuals for this batch\n",
    "                last_5_predictions = outputs.cpu().numpy()[-5:]\n",
    "                last_5_actuals = targets.cpu().numpy()[-5:]\n",
    "        \n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        \n",
    "        # Save checkpoint if this is the best model so far\n",
    "        if avg_test_loss < best_test_loss:\n",
    "            best_test_loss = avg_test_loss\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'best_model_epoch_{epoch+1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'test_loss': avg_test_loss,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"\\nSaved new best model with test loss: {avg_test_loss:.4f}\")\n",
    "        \n",
    "        print(f\"\\nEpoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(\"\\nLast 5 test samples for this epoch:\")\n",
    "        print(\"Predictions vs Actuals:\")\n",
    "        for i, (pred, actual) in enumerate(zip(last_5_predictions, last_5_actuals)):\n",
    "            print(f\"Sample {i+1}: Predicted = {pred[0]:.4f}, Actual = {actual[0]:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to load the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(model, checkpoint_dir='checkpoints'):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
    "    if not checkpoints:\n",
    "        return None, None\n",
    "    \n",
    "    # Get the checkpoint with the lowest test loss from the filename\n",
    "    best_checkpoint = sorted(checkpoints, key=lambda x: float(torch.load(os.path.join(checkpoint_dir, x))['test_loss']))[0]\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, best_checkpoint)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.ones_(m.weight)  # Set γ (scale) to 1\n",
    "        nn.init.zeros_(m.bias)   # Set β (shift) to 0\n",
    "\n",
    "# Example usage:\n",
    "# model = BaseModel2()\n",
    "# model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel2(\n",
      "  (conv1): Conv2d(21, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (hiddenlayer1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (hiddenlayer2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (norm4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (hiddenlayer3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (norm5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (output): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel2()\n",
    "model.apply(init_weights)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/40] Training: 100%|██████████| 313/313 [00:26<00:00, 11.90it/s, train_loss=1.5805] \n",
      "Epoch [1/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 46.05it/s, test_loss=0.5467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 1.0038\n",
      "\n",
      "Epoch [1/40], Train Loss: 8.7029, Test Loss: 1.0038\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.1821, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.9728, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.4842, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.1676, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.3613, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/40] Training: 100%|██████████| 313/313 [00:27<00:00, 11.22it/s, train_loss=0.6351]\n",
      "Epoch [2/40] Testing: 100%|██████████| 32/32 [00:01<00:00, 30.89it/s, test_loss=0.5063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/40], Train Loss: 1.1019, Test Loss: 1.0091\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.1048, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.9912, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.5257, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.1443, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.0832, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/40] Training: 100%|██████████| 313/313 [00:27<00:00, 11.44it/s, train_loss=0.3105]\n",
      "Epoch [3/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 47.39it/s, test_loss=0.5975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/40], Train Loss: 0.9043, Test Loss: 1.0254\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.0475, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.9081, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.4285, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.1349, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.1977, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/40] Training: 100%|██████████| 313/313 [00:26<00:00, 11.77it/s, train_loss=0.4801]\n",
      "Epoch [4/40] Testing: 100%|██████████| 32/32 [00:01<00:00, 31.07it/s, test_loss=0.4911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 0.9617\n",
      "\n",
      "Epoch [4/40], Train Loss: 0.8550, Test Loss: 0.9617\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.0218, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.0623, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.2310, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.3201, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.2778, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/40] Training: 100%|██████████| 313/313 [00:28<00:00, 11.16it/s, train_loss=0.4243]\n",
      "Epoch [5/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 45.50it/s, test_loss=0.4211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 0.9339\n",
      "\n",
      "Epoch [5/40], Train Loss: 0.7808, Test Loss: 0.9339\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.0571, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.2508, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.3035, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.2704, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.1445, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/40] Training: 100%|██████████| 313/313 [00:24<00:00, 12.64it/s, train_loss=0.3389]\n",
      "Epoch [6/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 43.94it/s, test_loss=0.5332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/40], Train Loss: 0.7396, Test Loss: 0.9891\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.0886, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.1927, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.1517, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.5344, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.2196, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/40] Training: 100%|██████████| 313/313 [00:26<00:00, 11.88it/s, train_loss=0.2547]\n",
      "Epoch [7/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 45.21it/s, test_loss=0.5392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/40], Train Loss: 0.7079, Test Loss: 0.9725\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.0531, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.1793, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.3322, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.4286, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.2869, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/40] Training: 100%|██████████| 313/313 [00:25<00:00, 12.43it/s, train_loss=0.3092]\n",
      "Epoch [8/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 45.23it/s, test_loss=0.6185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/40], Train Loss: 0.6977, Test Loss: 0.9936\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.1515, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.6055, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.2183, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.4750, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.2704, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/40] Training: 100%|██████████| 313/313 [00:26<00:00, 11.81it/s, train_loss=0.1798]\n",
      "Epoch [9/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 42.36it/s, test_loss=0.6712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/40], Train Loss: 0.6786, Test Loss: 1.0281\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.0101, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.5495, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.0748, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.5800, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.3727, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/40] Training: 100%|██████████| 313/313 [00:27<00:00, 11.29it/s, train_loss=0.1760]\n",
      "Epoch [10/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 41.80it/s, test_loss=0.6836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/40], Train Loss: 0.6503, Test Loss: 1.0144\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.0501, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.6634, Actual = -0.0279\n",
      "Sample 3: Predicted = -0.0063, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.6357, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.3473, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/40] Training: 100%|██████████| 313/313 [00:27<00:00, 11.35it/s, train_loss=0.1604]\n",
      "Epoch [11/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 42.86it/s, test_loss=0.6016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [11/40], Train Loss: 0.6216, Test Loss: 0.9756\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.0725, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.4669, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.0342, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.6050, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.2610, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/40] Training: 100%|██████████| 313/313 [00:28<00:00, 11.10it/s, train_loss=0.1803]\n",
      "Epoch [12/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 43.24it/s, test_loss=0.6053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [12/40], Train Loss: 0.6193, Test Loss: 0.9532\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.1461, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.0331, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.1017, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.6589, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.1511, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/40] Training: 100%|██████████| 313/313 [00:25<00:00, 12.12it/s, train_loss=0.2857]\n",
      "Epoch [13/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 44.22it/s, test_loss=0.5598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 0.9088\n",
      "\n",
      "Epoch [13/40], Train Loss: 0.6034, Test Loss: 0.9088\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.2244, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.3490, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.2271, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.5400, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.1063, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/40] Training: 100%|██████████| 313/313 [00:26<00:00, 11.62it/s, train_loss=0.2635]\n",
      "Epoch [14/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 34.24it/s, test_loss=0.6274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 0.8989\n",
      "\n",
      "Epoch [14/40], Train Loss: 0.5907, Test Loss: 0.8989\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.3468, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.1813, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.2337, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.4882, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.2195, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/40] Training: 100%|██████████| 313/313 [00:26<00:00, 11.97it/s, train_loss=0.3202]\n",
      "Epoch [15/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 44.65it/s, test_loss=0.5518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 0.8845\n",
      "\n",
      "Epoch [15/40], Train Loss: 0.5731, Test Loss: 0.8845\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.0648, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.0908, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.2880, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.5361, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.0308, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/40] Training: 100%|██████████| 313/313 [00:25<00:00, 12.14it/s, train_loss=0.2447]\n",
      "Epoch [16/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 44.06it/s, test_loss=0.6933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [16/40], Train Loss: 0.5509, Test Loss: 0.9584\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.2867, Actual = -0.0839\n",
      "Sample 2: Predicted = 0.0648, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.4396, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.6308, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.1255, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/40] Training: 100%|██████████| 313/313 [00:21<00:00, 14.57it/s, train_loss=0.1770]\n",
      "Epoch [17/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 47.69it/s, test_loss=0.6556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 0.8253\n",
      "\n",
      "Epoch [17/40], Train Loss: 0.5446, Test Loss: 0.8253\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.0602, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.0170, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.3311, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.4585, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.4083, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/40] Training: 100%|██████████| 313/313 [00:21<00:00, 14.57it/s, train_loss=0.1733]\n",
      "Epoch [18/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 45.35it/s, test_loss=0.8557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 0.8211\n",
      "\n",
      "Epoch [18/40], Train Loss: 0.5061, Test Loss: 0.8211\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.0513, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.0488, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.2056, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.3131, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.7549, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/40] Training: 100%|██████████| 313/313 [00:21<00:00, 14.44it/s, train_loss=0.2011]\n",
      "Epoch [19/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 45.94it/s, test_loss=1.0476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [19/40], Train Loss: 0.4735, Test Loss: 0.9528\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -0.0370, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.2074, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.2119, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.3423, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.7159, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/40] Training: 100%|██████████| 313/313 [00:21<00:00, 14.47it/s, train_loss=0.2308]\n",
      "Epoch [20/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 46.39it/s, test_loss=0.8402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with test loss: 0.7918\n",
      "\n",
      "Epoch [20/40], Train Loss: 0.4612, Test Loss: 0.7918\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.6580, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.1817, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.1843, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.4623, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.2130, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/40] Training: 100%|██████████| 313/313 [00:21<00:00, 14.25it/s, train_loss=0.3702]\n",
      "Epoch [21/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 45.90it/s, test_loss=1.1485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [21/40], Train Loss: 0.4357, Test Loss: 0.8312\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.8909, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.1327, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.3761, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.5894, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.0135, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/40] Training: 100%|██████████| 313/313 [00:23<00:00, 13.37it/s, train_loss=0.2663]\n",
      "Epoch [22/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 36.46it/s, test_loss=1.7063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [22/40], Train Loss: 0.4156, Test Loss: 1.8008\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 2.0117, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.1597, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.2790, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.7957, Actual = -0.8060\n",
      "Sample 5: Predicted = 1.1180, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/40] Training: 100%|██████████| 313/313 [00:22<00:00, 14.05it/s, train_loss=0.2836]\n",
      "Epoch [23/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 48.40it/s, test_loss=1.0193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [23/40], Train Loss: 0.3911, Test Loss: 0.8952\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 0.4467, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.1603, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.1529, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.2229, Actual = -0.8060\n",
      "Sample 5: Predicted = -0.4730, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/40] Training: 100%|██████████| 313/313 [00:26<00:00, 11.95it/s, train_loss=0.2057]\n",
      "Epoch [24/40] Testing: 100%|██████████| 32/32 [00:00<00:00, 41.97it/s, test_loss=1.0805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [24/40], Train Loss: 0.3671, Test Loss: 1.4195\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 1.5789, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.2120, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.3142, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.4998, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.5699, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/40] Training: 100%|██████████| 313/313 [00:29<00:00, 10.79it/s, train_loss=0.1910]\n",
      "Epoch [25/40] Testing: 100%|██████████| 32/32 [00:01<00:00, 29.98it/s, test_loss=1.1868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [25/40], Train Loss: 0.3382, Test Loss: 1.6731\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = 1.5899, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.1819, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.5370, Actual = 0.1760\n",
      "Sample 4: Predicted = 0.5540, Actual = -0.8060\n",
      "Sample 5: Predicted = 0.8250, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/40] Training: 100%|██████████| 313/313 [00:28<00:00, 11.06it/s, train_loss=0.2142]\n",
      "Epoch [26/40] Testing: 100%|██████████| 32/32 [00:01<00:00, 30.40it/s, test_loss=3.2159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [26/40], Train Loss: 0.3482, Test Loss: 1.9196\n",
      "\n",
      "Last 5 test samples for this epoch:\n",
      "Predictions vs Actuals:\n",
      "Sample 1: Predicted = -1.3474, Actual = -0.0839\n",
      "Sample 2: Predicted = -0.2859, Actual = -0.0279\n",
      "Sample 3: Predicted = 0.4336, Actual = 0.1760\n",
      "Sample 4: Predicted = -0.0063, Actual = -0.8060\n",
      "Sample 5: Predicted = -1.4962, Actual = -0.3150\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/40] Training:  31%|███       | 97/313 [00:09<00:20, 10.38it/s, train_loss=0.4222]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(model,train_loader,test_loader)\n",
      "Cell \u001b[0;32mIn[66], line 41\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, epochs, lr, alpha, checkpoint_dir)\u001b[0m\n\u001b[1;32m     38\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     39\u001b[0m train_pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_pbar:\n\u001b[1;32m     42\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     43\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m, in \u001b[0;36mChessloader.__getitem__\u001b[0;34m(self, ind)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,ind) :\n\u001b[1;32m     10\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[ind]\n\u001b[0;32m---> 11\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encoding(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEN\u001b[39m\u001b[38;5;124m'\u001b[39m]),dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     12\u001b[0m     target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluation_std\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor,target\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model,train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
